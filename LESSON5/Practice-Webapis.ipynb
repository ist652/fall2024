{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swagger Demo: Web APIs\n",
    "\n",
    "## Overview\n",
    "\n",
    "The key to making device consumption work are Web API's (Application Program Interfaces accessible over the Internet). Products we use everyday like smartphones, Amazon's Alexa, and gaming consoles all rely on web API's. They seem \"smart\" and \"powerful\" but in actuality they're only interfacing with smart and powerful services in the cloud.\n",
    "\n",
    "API consumption is the new reality of programming; it is why we cover it in this course. Once you undersand how to conusme API's you can write a program to do almost anything and harness the power of the internet to make **your own programs look \"smart\" and \"powerful.\"** \n",
    "\n",
    "## CENT IoT Portal\n",
    "\n",
    "This is a walk-through for how to use some of the Web API's in the iSchool IoT Portal. For each web API we will discover common use cases.\n",
    "\n",
    "**Before you start the lab login to the IoT portal with your netid and copy your APIKey**\n",
    "\n",
    "[https://cent.ischool-iot.net](https://cent.ischool-iot.net)\n",
    "\n",
    "Note you will also need to visit the Api Docs page, here:\n",
    "\n",
    "[https://cent.ischool-iot.net/doc](https://cent.ischool-iot.net/doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_cell_type": "run_code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start by importing the modules we will need\n",
    "import requests\n",
    "import json \n",
    "import pandas as pd\n",
    "\n",
    "APIKEY = \"your key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure AI API\n",
    "\n",
    "The Azure AI API allows you to extract meaning from text. Here, we will explore 3 services:\n",
    "\n",
    "- Entity Recognition - Identify and extract entities from text.\n",
    "- Key Phrase extraction - Identify and key phrases from large quantities of text.\n",
    "- Sentiment - Dervie sentiment / mood from text.\n",
    "\n",
    "\n",
    "These are 3 common activities found in the discipline known as **text mining**, which is a form of **NLP (Natural Language Processing**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Recognition\n",
    "\n",
    "Find `/api/azure/entityrecognition` in the API Docs.\n",
    "\n",
    "How is this API called?  Is it a get or a Post? What is the input?  What is the output format?\n",
    "\n",
    "With that decided, let's extract entities from the following phrase:\n",
    "\n",
    "    \"I would not pay $5 to see that Star Wars movie next week when I am in Buffalo.\"\n",
    "    \n",
    "Here is code to call the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_cell_type": "run_code",
    "tags": []
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error: BAD REQUEST for url: https://cent.ischool-iot.net/api/azure/entityrecognition",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-API-KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m: APIKEY}  \u001b[38;5;66;03m# Header input\u001b[39;00m\n\u001b[1;32m      5\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url, headers\u001b[38;5;241m=\u001b[39mheaders, data\u001b[38;5;241m=\u001b[39mtext_input) \u001b[38;5;66;03m# Make the request\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Raise Error if not 200\u001b[39;00m\n\u001b[1;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson() \u001b[38;5;66;03m# deserialize\u001b[39;00m\n\u001b[1;32m      8\u001b[0m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: BAD REQUEST for url: https://cent.ischool-iot.net/api/azure/entityrecognition"
     ]
    }
   ],
   "source": [
    "text_input = {\"text\": \"I would not pay $5 to see that Star Wars movie next week when I am in Buffalo.\"}\n",
    "\n",
    "url = \"https://cent.ischool-iot.net/api/azure/entityrecognition\"  #URL\n",
    "headers = {\"X-API-KEY\": APIKEY}  # Header input\n",
    "response = requests.post(url, headers=headers, data=text_input) # Make the request\n",
    "response.raise_for_status() # Raise Error if not 200\n",
    "data = response.json() # deserialize\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What happened? \n",
    "\n",
    "It looks like the API extracted 3 entities. These are located at the following key:  `data['results']['documents'][0]['entities']`\n",
    "\n",
    "For this API call, this is where the entities will be.  It should be noted that where to look for what you need will depend on the API call and the results.\n",
    "\n",
    "Let's put these results, which are a list into a dataframe!  **Important: Make sure you see the comparision between the DataFrame and the JSON output in the cell above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.json_normalize(data['results']['documents'][0]['entities'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breaking down the request with another example\n",
    "\n",
    "The approach to coding a web API call is always the same:\n",
    "\n",
    "1. Setup inputs necessary for the API\n",
    "2. Make request (call web API)\n",
    "3. Make sure response is ok / not an error\n",
    "4. Deserialize the response\n",
    "5. Do something with the outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_cell_type": "run_code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in the email file\n",
    "with open(\"email.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# INPUT\n",
    "text_input = {\"text\": text }\n",
    "\n",
    "# PROCESS\n",
    "url = \"https://cent.ischool-iot.net/api/azure/entityrecognition\"  #URL\n",
    "headers = {\"X-API-KEY\": APIKEY }  # Header input\n",
    "response = requests.post(url, headers=headers, data=text_input) # Make the request\n",
    "response.raise_for_status() # Raise Error if not 200\n",
    "data = response.json() # deserialize\n",
    "\n",
    "#OUTPUT\n",
    "df = pd.json_normalize(data['results']['documents'][0]['entities']) # find what we need in the output\n",
    "\n",
    "df # Show the output... Warning! Its a lot of data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curious as to what categories were detected?\n",
    "\n",
    "Let's check out the categories! You can see entity recognition will attempt to detect a lot of different things from People, to Dates, quantities, and organizations, to more structured data like email addresses, phone numbers, credir cards, and urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It finds a lot of entities, but we only want the emails!\n",
    "\n",
    "In a dataframe, so that's just a boolean index filter! Let5's just get the extracted emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emaildf = df[ df['category'] == \"Email\"]\n",
    "emaildf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of unique emails\n",
    "\n",
    "To get a list of unique emails, we can now deduplicate and sort the series. We have done this a few times before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emails = sorted(list(emaildf['text'].dropna().unique()))\n",
    "print(emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 You Code create a function\n",
    "\n",
    "\n",
    "Its useful to wrap the Web API calls in a function. It makes it easier to reuse them and purpose them in the `apply()` method of a dataframe.\n",
    "\n",
    "Re-write the examples from the cells above in this section as a single function. \n",
    "\n",
    "Take text as input, output a list of unique emails from the text. The function definition, and an detailed algorithm are provided.\n",
    "\n",
    "`def extract_emails(text: str) -> list:`\n",
    "\n",
    "    1) setup the inputs from text\n",
    "    2) call the web api\n",
    "    3) raise if not successful\n",
    "    4) deserialize\n",
    "    5) create a dataframe from list of named entities\n",
    "    6) filter data frame to only emails\n",
    "    7) sort and deduplicate the emails\n",
    "    8) return list of emails\n",
    "    \n",
    "In the cell below 1.1 some test code has been provided for you.  Again the goal is to write the function to pass the test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_cell_type": "write_code",
    "label": "1.1",
    "solution": [
     "def extract_emails(text: str) -> list:\n",
     "    # INPUT\n",
     "    text_input = {'text': text}\n",
     "    # PROCESS\n",
     "    url = 'https://cent.ischool-iot.net/api/azure/entityrecognition'\n",
     "    headers = {'X-API-KEY': APIKEY}\n",
     "    response = requests.post(url, headers=headers, data=text_input)\n",
     "    response.raise_for_status()\n",
     "    data = response.json()\n",
     "    #OUTPUT\n",
     "    df = pd.json_normalize(data['results']['documents'][0]['entities'])\n",
     "    dfe = df[df['category'] == 'Email']\n",
     "    emails = sorted(list(dfe['text'].dropna().unique()))\n",
     "    return emails\n"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO Write function defintion code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Test code for your function in 1.1\n",
    "\n",
    "Run this code to test the function you wrote in 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Test!\n",
    "text = '''As of this year, my primary email address is test@syr.edu but I \n",
    "    also use testing@gmail.com and tester@aol.com from time to time, \n",
    "    but test@syr.edu is the main one.'''\n",
    "expect = ['testinge@gmail.com', 'test@syr.edu', 'tester@aol.com']\n",
    "actual = extract_emails(text)\n",
    "print(\"EXPECT:\", expect, \"ACTUAL:\", actual)\n",
    "assert expect == actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Phrase Extraction\n",
    "\n",
    "Find `/api/azure/keyphrasextration` in the Api Docs. Review how to call this API.\n",
    "\n",
    "Key Phrase extraction extracts the subjects from the text. This can be used to determine what someone it talking about. \n",
    "\n",
    "\n",
    "Let's try it out: Here's are three sample reviews of a restaraunt. What are these is this reviewers talking about? \n",
    "\n",
    "    '''\n",
    "    review1 = \"I don't think I will ever order the eggs again. They were runny Yuk!\"\n",
    "    review2 = \"Went there last Wednesday and it was busy, which is good to see. The pancakes and eggs were spot on! I enjoyed my meal and would recommend a visit.\"\n",
    "    review3 = \"Not sure who is running the place but the eggs benedict were not that great. No flavor. At least my toast wasn't burnt.\"\n",
    "    '''\n",
    "    \n",
    "Let's call the API with the 1st review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_cell_type": "run_code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "review1 = \"I don't think I will ever order the scrambled eggs again. They were runny. It looked like snot!\"\n",
    "review2 = \"Went there last Wednesday and it was busy, which is good to see. The pancakes and eggs were spot on! I enjoyed my meal and would recommend a visit.\"\n",
    "review3 = \"Not sure who is running the place but the eggs benedict were not that great. No flavor. At least my toast wasn't burnt.\"\n",
    "\n",
    "text_input = {\"text\": review1}\n",
    "\n",
    "# PROCESS\n",
    "url = \"https://cent.ischool-iot.net/api/azure/keyphrasextraction\"\n",
    "headers = {\"X-API-KEY\": APIKEY}\n",
    "response = requests.post(url, headers=headers, data=text_input)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "#OUTPUT\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the phrases\n",
    "\n",
    "For this API, the output is under `data['results']['documents'][0]['keyPhrases']`\n",
    "\n",
    "Let's extract them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key_phrases = data['results']['documents'][0]['keyPhrases']\n",
    "print(key_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Rewriting Key Phrase Extraction as a function\n",
    "\n",
    "Once again, let's wrap this API call in a user-defined function. This time the function will be written for you and you must write the test.\n",
    "\n",
    "`def extract_keyphrases(text: str) -> list:`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function written for you\n",
    "def extract_keyphrases(text: str) -> list:\n",
    "    #INPUT\n",
    "    text_input = {\"text\": text}\n",
    "\n",
    "    # PROCESS\n",
    "    url = \"https://cent.ischool-iot.net/api/azure/keyphrasextraction\"\n",
    "    headers = {\"X-API-KEY\": APIKEY}\n",
    "    response = requests.post(url, headers=headers, data=text_input)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "\n",
    "    #OUTPUT\n",
    "    phrases = data['results']['documents'][0]['keyPhrases']\n",
    "    return phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 You Code testing The `extract_keyphrases()` function\n",
    "\n",
    "Write code similar to the test code in 1.1 but this time you should test the `extract_keyphrases()` function. Just write a single test.\n",
    "\n",
    "Here's the process:\n",
    "\n",
    "    1) Make up some text phrase. Make sure it has a subject that can be extracted. examples:\n",
    "        \"The Xbox is the best video gaming console.\"\n",
    "        \"The wise consumer uses their credit cards sparingly\"\n",
    "        You are STRONGLY encouraged to use your own phrase here.\n",
    "    2) Call your function with your example as input and observe the output. Did it work?\n",
    "    3) Re-write as test code:\n",
    "        a) input_text = your text phrase\n",
    "        b) expected = output from 2)\n",
    "        c) actual = code from 2)\n",
    "        d) print and assert expected == actual\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_cell_type": "write_code",
    "label": "1.2",
    "solution": [
     "input_text = 'The Xbox is the best video gaming console.'\n",
     "expect = ['best video gaming console', 'The Xbox']\n",
     "actual =  extract_keyphrases(input_text)\n",
     "print('EXPECT:', expect, 'ACTUAL:', actual)\n",
     "assert expect == actual\n"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO Write one test here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "Find `/api/azure/sentiment` in the Api Docs. Review how to call this API\n",
    "\n",
    "Sentiment determines the mood of the text. It is positive or negative, for example?\n",
    "\n",
    "We saw sentiment before, but this time it will be much more accurate!\n",
    "\n",
    "Let's try it out: Again the three sample reviews of a restaraunt. Are these reviews \"positive\" or \"negative\"?\n",
    "\n",
    "    '''\n",
    "    review1 = \"I don't think I will ever order the eggs again. They were runny Yuk!\"\n",
    "    review2 = \"Went there last Wednesday. It was crowded and the pancakes and eggs were spot on! I enjoyed my meal and would recommend a visit.\"\n",
    "    review3 = \"Not sure who is running the place but the eggs benedict were not that great. No flavor. At least my toast wasn't burnt.\"\n",
    "    '''\n",
    "    \n",
    "Let's call the API with the 2nd review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_input = {\"text\": review2}\n",
    "\n",
    "# PROCESS\n",
    "url = \"https://cent.ischool-iot.net/api/azure/sentiment\"\n",
    "headers = {\"X-API-KEY\": APIKEY}\n",
    "response = requests.post(url, headers=headers, data=text_input)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "#OUTPUT\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment output is complex!\n",
    "\n",
    "You can see the input text was broken up into individual sentences. Each sentence was analyzed for sentiment.\n",
    "\n",
    "The overall sentiment is under the key: `data['results']['documents'][0]['sentiment']`\n",
    "\n",
    "The scores are under the key: `data['results']['documents'][0]['confidenceScores']`\n",
    "\n",
    "Let's extract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment = data['results']['documents'][0]['sentiment']\n",
    "scores = data['results']['documents'][0]['confidenceScores']\n",
    "print(sentiment, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Writing the `extract_sentiment()` function\n",
    "\n",
    "Once again, let's write a function to wrap the web API. \n",
    "\n",
    "`def extract_sentiment(text: str) -> tuple[str, str]:`\n",
    "\n",
    "No algorithm is provided this time, **by now you should realize the structure of these functions is always the same.** What differs is the actual URL and how exactly to extract what you want from the JSON output, and the code above demonstrates how that is done.\n",
    "\n",
    "In this case, we want to return a two values:\n",
    "\n",
    "`return sentiment, scores`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_cell_type": "debug_code",
    "label": "1.3",
    "solution": [
     "def extract_sentiment(text: str) -> tuple[str, str]:\n",
     "    text_input = {'text': text}\n",
     "    url = 'https://cent.ischool-iot.net/api/azure/sentiment'\n",
     "    headers = {'X-API-KEY': APIKEY}\n",
     "    response = requests.post(url, headers=headers, data=text_input)\n",
     "    response.raise_for_status()\n",
     "    data = response.json()\n",
     "    sentiment = data['results']['documents'][0]['sentiment']\n",
     "    scores = data['results']['documents'][0]['confidenceScores']\n",
     "    return sentiment, scores\n"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO write function code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the `extract_sentiment()` function\n",
    "\n",
    "Run this code to ensure your function was written properly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test \n",
    "input_text = 'I like scotch. Scotchy-scotch, scotch. Tastes so good.'\n",
    "expect_sentiment = 'positive'\n",
    "expect_scores = {'positive': 0.88, 'neutral': 0.1, 'negative': 0.01}\n",
    "sentiment, scores = extract_sentiment(input_text)\n",
    "print(\"EXPECT:\", expect_sentiment, expect_scores, \"ACTUAL:\", sentiment, scores)\n",
    "assert expect_sentiment == sentiment\n",
    "assert expect_scores == scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that you know about the fundamentals of text AI, what can you do with it?\n",
    "\n",
    "There are a variety of uses for text AI. Let me provide an example of how this could be used if you owned a chain of restaurants. \n",
    "\n",
    "1. You can take customer Yelp and Google reviews and run sentiment analysis to determine how customers feel about it. \n",
    "2. Extract key phrases to understand what the are talking about. For example, they like the food but dislike the service. The like the pizza.\n",
    "2. Use named entity recognition get indications of pricing. \"$15 is too high for a hamburger\",  or location / date \"I visited from Buffalo last thursday and the service was slow.\"\n",
    "3. Use key phrase extraction to determine what they are talking about? Pancakes, breakfast sandwiches, eggs, pizza, food, service, location, etc...\n",
    "\n",
    "What I've outlined is a form of **opinion mining**, which is a very specific application of **text mining**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Last Example: Sentiment and Key Phrase Extraction: \n",
    "\n",
    "    \"Two great tastes that taste great together.\"\n",
    "\n",
    "When we combine sentiment with key phrase extraction we not only know what they are talking about but how they feel about it. This is a powerful form of analysis that is essential to opinion mining.\n",
    "\n",
    "Let's write a program that takes input text then outputs the sentiment and keyphrases. Call the functions you wrote in 1.2 and 1.3 to complete this activity. Make sure your output follows the example here. The entire program is 4 lines of code. \n",
    "\n",
    "    EXAMPLE RUN  #1\n",
    "    Enter Text: Their pizza is the best in town\n",
    "    The text mentions ['pizza', 'town'] in a positive way.\n",
    "        \n",
    "    EXAMPLE RUN  #2    \n",
    "    Enter Text: Goats milk is gross.\n",
    "    The text mentions ['Goats milk'] in a negative way.\n",
    "    \n",
    "    EXAMPLE RUN  #3\n",
    "    Enter Text: The new york yankees as the most despised baseball program in the major leagues.\n",
    "    The text mentions ['new york yankees', 'baseball program', 'major leagues'] in a negative way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 You Code\n",
    "\n",
    "Write the program here. No need to use an interact a simple `input()` and `print()` will suffice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_cell_type": "write_code",
    "label": "1.4",
    "solution": [
     "text = input('Enter Text:')\n",
     "phrases = extract_keyphrases(text)\n",
     "sentiment, score = extract_sentiment(text)\n",
     "print(f'The text mentions {phrases} in a {sentiment} way.')\n"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO write code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
