{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "388ae8e0-0974-4626-85c3-98c51a57f229",
   "metadata": {},
   "source": [
    "### MIDTERM PRACTICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e813644-8f68-4bad-ab26-20c9cb4daf0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### QUESTION 1 \n",
    "\n",
    "#### Write a  Pandas program to create and display a one-dimensional array-like object containing an array of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dbb6257-5c75-489a-bc7d-873cda2e915a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 10, 20]\n"
     ]
    }
   ],
   "source": [
    "a=[1,4,10,20]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c5d32-21f4-41fb-a9bd-585599c02019",
   "metadata": {},
   "source": [
    "#### QUESTION 2\n",
    "\n",
    "#### I have a dataset with the variable name data. What is a correct syntax to create a Pandas DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86225000-1116-4ffb-a6d0-a015b6eab982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0\n",
      "0   1\n",
      "1   4\n",
      "2  10\n",
      "3  20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(a)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10aa420-752d-47cd-9406-1d460fc2b9ab",
   "metadata": {},
   "source": [
    "#### QUESTION 3\n",
    "\n",
    "#### What is a correct syntax to return the first row in a Pandas DataFrame with the variable name df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50331eea-9a72-4af7-8fc0-ff276c0e4616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ca9b66d-62a6-4232-bb6b-4901b9c1fbca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872694cf-5c77-432b-860d-336967252191",
   "metadata": {},
   "source": [
    "#### QUESTION 4\n",
    "\n",
    "#### What is a correct syntax to return both the first row and the second row in a Pandas DataFrame with the variable name df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a332627-497d-4a09-ad68-c1d95fe8a135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.iloc[0:2]\n",
    "df.iloc[[0,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a134e-d3e4-4e7a-9e26-a9f0894a6525",
   "metadata": {},
   "source": [
    "#### QUESTION 5\n",
    "\n",
    "#### What is a correct syntax to return the first 20 rows of a DataFrame with the variable name df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5302f92-f8a2-4359-9a80-a7822ad91676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0\n",
      "0   1\n",
      "1   4\n",
      "2  10\n",
      "3  20\n"
     ]
    }
   ],
   "source": [
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a388fb0a-7168-45b4-9913-4823acab99b6",
   "metadata": {},
   "source": [
    "#### QUESTION 6\n",
    "\n",
    "#### What is a correct syntax to return the entire DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aedb6564-abb2-473b-8f11-50e65c655139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0   1\n",
       "1   4\n",
       "2  10\n",
       "3  20"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323c0bb8-bf10-4600-949a-5479e1d6e4ab",
   "metadata": {},
   "source": [
    "#### QUESTION 7\n",
    "\n",
    "#### What is the Pandas function for loading JSON files into a DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58d525bb-9d86-4b2d-bba1-99df24aeb6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2054/1909173589.py:2: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(url)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/json/_json.py:804\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/json/_json.py:1014\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object_parser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_lines(data_lines))\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1014\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mconvert_dtypes(\n\u001b[1;32m   1017\u001b[0m         infer_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype_backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype_backend\n\u001b[1;32m   1018\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/json/_json.py:1040\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m   1038\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1040\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/json/_json.py:1173\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1173\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1176\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/json/_json.py:1366\u001b[0m, in \u001b[0;36mFrameParser._parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1362\u001b[0m orient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\n\u001b[1;32m   1364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[0;32m-> 1366\u001b[0m         \u001b[43mujson_loads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1367\u001b[0m     )\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1369\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1370\u001b[0m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[1;32m   1371\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ujson_loads(json, precise_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecise_float)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1372\u001b[0m     }\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "url = \"\"\n",
    "df = pd.read_json(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de41410f-3a05-48fa-bc40-fe5c4df30d5a",
   "metadata": {},
   "source": [
    "#### QUESTION 8\n",
    "\n",
    "#### What is syntax to load a Python Dictionary called \"data\" into a Pandas DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "beb1c0b3-4b11-4384-aba7-4e0d80082a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age\n",
       "0  18\n",
       "1  20"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={\n",
    "    'age' : ['18','20'],\n",
    "}\n",
    "\n",
    "new_df=pd.DataFrame(data)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a20f06e-d45f-44ac-a62e-9e847d22a4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283a7e59-a83f-47da-81a6-5777a7333882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a571f02-0ebb-4217-8f1f-bffc18709ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "368edbbe-abee-45db-8b94-f9980ef92a73",
   "metadata": {},
   "source": [
    "#### QUESTION 9\n",
    "\n",
    "#### What is a Pandas method for removing rows that contains empty cells?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1d3679-9d27-458f-98e2-dc677b802218",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = df.dropna()\n",
    "new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302ed314-e2c4-41f8-94ec-0c0a27473987",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### QUESTION 10\n",
    "#### Write a  Pandas program to convert a Panda module Series to  Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bbd5e41-6541-492c-b606-f668665cb5ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 34]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=pd.Series([1,2,34])\n",
    "type(s)\n",
    "s.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8780d64b-1c81-4b9c-8621-720f5440a7c9",
   "metadata": {},
   "source": [
    "#### QUESTION 11\n",
    "#### View the following dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ca89e5a-8e6b-4bcb-8dcd-a3c5058e9b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "student_data = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'age': [12, 12, 13, 13, 14, 12],\n",
    "    'height': [173, 192, 186, 167, 151, 159],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "\n",
    "print(student_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b648e9-1d92-4544-85de-0ae6288faba6",
   "metadata": {},
   "source": [
    "#### Write a  Pandas program to split the following dataframe into groups based on school code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6aaf867-d46c-47cb-8ac0-a3b5eb4ac65e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s001    school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S4  street1  \n",
      "s002    school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S2        s002     V  Gino Mcneill     17/05/2002   12     192      32   \n",
      "S5        s002     V  Gino Mcneill     11/05/2002   14     151      31   \n",
      "\n",
      "    address  \n",
      "S2  street2  \n",
      "S5  street2  \n",
      "s003    school_code class         name date_Of_Birth   age  height  weight  address\n",
      "S3        s003    VI  Ryan Parkes     16/02/1999   13     186      33  street3\n",
      "s004    school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S6        s004    VI  David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S6  street4  \n"
     ]
    }
   ],
   "source": [
    "sch_code = student_data.groupby('school_code')\n",
    "for school_code, group in sch_code:\n",
    "    print(school_code, group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cccf39-623b-40f5-a4f1-b67bfa6f513a",
   "metadata": {},
   "source": [
    "#### Write a Pandas program to split the following dataframe by school code and get mean, min, and max value of age for each school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d0ba24-2eae-4212-8b0b-74899df71abc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean, min, and max value of age for each value of the school:\n",
      "              age        \n",
      "             mean min max\n",
      "school_code              \n",
      "s001         12.5  12  13\n",
      "s002         13.0  12  14\n",
      "s003         13.0  13  13\n",
      "s004         12.0  12  12\n"
     ]
    }
   ],
   "source": [
    "# My suggestion\n",
    "# # Group by school_code and calculate mean, min, and max for the 'age' column\n",
    "# Using the agg method to include a list of functions\n",
    "\n",
    "print('\\nMean, min, and max value of age for each value of the school:')\n",
    "grouped_single = student_data.groupby('school_code').agg({'age': ['mean', 'min', 'max']})\n",
    "print(grouped_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c7ca598d-f076-4139-91b0-633ce9bf77f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sch_code \u001b[38;5;241m=\u001b[39m student_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschool_code\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m school_code, group \u001b[38;5;129;01min\u001b[39;00m sch_code:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(school_code, group)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#print(group['age'].aggregate(mean))\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#grouped = pd.df[sch_code]('age').agg(min,mean,max)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "sch_code = student_data.groupby('school_code').mean('age')\n",
    "for school_code, group in sch_code:\n",
    "    print(school_code, group)\n",
    "    #print(group['age'].aggregate(mean))\n",
    "    \n",
    "#grouped = pd.df[sch_code]('age').agg(min,mean,max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc3f29f9-2ea7-422d-8c55-19af2320dd3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2054/1567464985.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstudent_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11331\u001b[0m         \u001b[0mskipna\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11332\u001b[0m         \u001b[0mnumeric_only\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11333\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11334\u001b[0m     ):\n\u001b[0;32m> 11335\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11337\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11338\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11988\u001b[0m         \u001b[0mskipna\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11989\u001b[0m         \u001b[0mnumeric_only\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11990\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11991\u001b[0m     ) -> Series | float:\n\u001b[0;32m> 11992\u001b[0;31m         return self._stat_function(\n\u001b[0m\u001b[1;32m  11993\u001b[0m             \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11994\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11945\u001b[0m         \u001b[0mnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11947\u001b[0m         \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"skipna\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_allowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11949\u001b[0;31m         return self._reduce(\n\u001b[0m\u001b[1;32m  11950\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11951\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m  11101\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mfilter_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfilter_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"bool\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11102\u001b[0m         \u001b[0mout_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bool\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilter_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"bool\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11105\u001b[0;31m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11107\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11108\u001b[0m             \u001b[0;31m# We only use this in the case that operates on self.values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_TO_AXIS_NUMBER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No axis named {axis} for object type {cls.__name__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "student_data.mean(['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f87a3-52fe-4f9a-bed6-45f2484ecbd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### QUESTION 12\n",
    "#### View the following dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86d34846-f2ca-4c90-b2b9-f2afc4c87479",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Orders DataFrame:\n",
      "    ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
      "0    70001     150.50  2012-10-05         3001         5002\n",
      "1    70009     270.65  2012-09-10         3001         5005\n",
      "2    70002      65.26  2012-10-05         3005         5001\n",
      "3    70004     110.50  2012-08-17         3001         5003\n",
      "4    70007     948.50  2012-09-10         3005         5002\n",
      "5    70005    2400.60  2012-07-27         3001         5001\n",
      "6    70008    5760.00  2012-09-10         3005         5001\n",
      "7    70010    1983.43  2012-10-10         3001         5006\n",
      "8    70003    2480.40  2012-10-10         3005         5003\n",
      "9    70012     250.45  2012-06-27         3001         5002\n",
      "10   70011      75.29  2012-08-17         3005         5007\n",
      "11   70013    3045.60  2012-04-25         3005         5001\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
    "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[3001,3001,3005,3001,3005,3001,3005,3001,3005,3001,3005,3005],\n",
    "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
    "print(\"Original Orders DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea78cafa-4ebc-467f-88dd-cd5dffe1bf1c",
   "metadata": {},
   "source": [
    "#### Write a  Pandas program to split a dataset to group by two columns and then sort the aggregated results within the groups. Group on 'customer_id', 'salesman_id' and then sort sum of purch_amt within the groups. Use nlargest() to obtain the largest 5 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f820e2-c2bf-4c4a-8f06-e96bb7ebd229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group on 'customer_id', 'salesman_id' and then sort sum of purch_amt within the groups:\n",
      "customer_id  salesman_id\n",
      "3005         5001           8870.86\n",
      "             5003           2480.40\n",
      "3001         5001           2400.60\n",
      "             5006           1983.43\n",
      "3005         5002            948.50\n",
      "Name: purch_amt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# I am grouping by customer_id and salesman_id, sum the purch_amt within each group, and then sort the groups by the sum to show the largest five values. \n",
    "\n",
    "# Grouping by 'customer_id' and 'salesman_id' and summing 'purch_amt'\n",
    "df_agg = df.groupby(['customer_id', 'salesman_id']).agg({'purch_amt': 'sum'})\n",
    "# Extracting the 'purch_amt' column\n",
    "result = df_agg['purch_amt']\n",
    "\n",
    "# Printing the top 5 highest sums\n",
    "print(\"\\nGroup on 'customer_id', 'salesman_id' and then sort sum of purch_amt within the groups:\")\n",
    "print(result.nlargest(5))  # specify how many of the largest you want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f01e42a-d92b-4c95-a863-7b342c5e4846",
   "metadata": {},
   "source": [
    "#### QUESTION 13\n",
    "\n",
    "#### Write a  Pandas program to join the two given dataframes along **rows** and assign all data.\n",
    "\n",
    "#### Write a  Pandas program to join the two given dataframes along **columns** and assign all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c6064fa-0863-40ba-b517-8491bd93fa37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "student_data1 = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'], \n",
    "        'points': [200, 210, 190, 222, 199]})\n",
    "\n",
    "student_data2 = pd.DataFrame({\n",
    "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
    "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'], \n",
    "        'points': [201, 200, 198, 219, 201]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9b43ee6-30e2-42ea-a9bd-92633d602e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      "  student_id              name  points\n",
      "0         S1  Danniella Fenton     200\n",
      "1         S2      Ryder Storey     210\n",
      "2         S3      Bryce Jensen     190\n",
      "3         S4         Ed Bernal     222\n",
      "4         S5       Kwame Morin     199\n",
      "-------------------------------------\n",
      "  student_id              name  points\n",
      "0         S4  Scarlette Fisher     201\n",
      "1         S5  Carla Williamson     200\n",
      "2         S6       Dante Morse     198\n",
      "3         S7    Kaiser William     219\n",
      "4         S8   Madeeha Preston     201\n",
      "\n",
      "Join the said two dataframes along rows:\n",
      "  student_id              name  points\n",
      "0         S1  Danniella Fenton     200\n",
      "1         S2      Ryder Storey     210\n",
      "2         S3      Bryce Jensen     190\n",
      "3         S4         Ed Bernal     222\n",
      "4         S5       Kwame Morin     199\n",
      "0         S4  Scarlette Fisher     201\n",
      "1         S5  Carla Williamson     200\n",
      "2         S6       Dante Morse     198\n",
      "3         S7    Kaiser William     219\n",
      "4         S8   Madeeha Preston     201\n"
     ]
    }
   ],
   "source": [
    "#  Join the two given dataframes along rows and assign all data\n",
    "\n",
    "print(\"Original DataFrames:\")\n",
    "print(student_data1)\n",
    "print(\"-------------------------------------\")\n",
    "print(student_data2)\n",
    "print(\"\\nJoin the said two dataframes along rows:\")\n",
    "result_data = pd.concat([student_data1, student_data2])\n",
    "print(result_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9b3545d-6c1e-4173-a08b-64bde222eeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      "  student_id              name  points\n",
      "0         S1  Danniella Fenton     200\n",
      "1         S2      Ryder Storey     210\n",
      "2         S3      Bryce Jensen     190\n",
      "3         S4         Ed Bernal     222\n",
      "4         S5       Kwame Morin     199\n",
      "-------------------------------------\n",
      "  student_id              name  points\n",
      "0         S4  Scarlette Fisher     201\n",
      "1         S5  Carla Williamson     200\n",
      "2         S6       Dante Morse     198\n",
      "3         S7    Kaiser William     219\n",
      "4         S8   Madeeha Preston     201\n",
      "\n",
      "Join the said two dataframes along columns:\n",
      "  student_id              name  points student_id              name  points\n",
      "0         S1  Danniella Fenton     200         S4  Scarlette Fisher     201\n",
      "1         S2      Ryder Storey     210         S5  Carla Williamson     200\n",
      "2         S3      Bryce Jensen     190         S6       Dante Morse     198\n",
      "3         S4         Ed Bernal     222         S7    Kaiser William     219\n",
      "4         S5       Kwame Morin     199         S8   Madeeha Preston     201\n"
     ]
    }
   ],
   "source": [
    "# Join the two given dataframes along columns and assign all data.\n",
    "\n",
    "print(\"Original DataFrames:\")\n",
    "print(student_data1)\n",
    "print(\"-------------------------------------\")\n",
    "print(student_data2)\n",
    "print(\"\\nJoin the said two dataframes along columns:\")\n",
    "result_data2 = pd.concat([student_data1, student_data2], axis = 1)\n",
    "print(result_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4cf99a-6e59-4699-8371-2de0bc97b804",
   "metadata": {},
   "source": [
    "#### QUESTION 14\n",
    "\n",
    "#### Write a  Pandas program to append rows in s6 to an existing DataFrame and display the combined data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c75332b6-5fce-4dcc-8282-8ba7cd8c1cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student_id                  S6\n",
       "name          Scarlette Fisher\n",
       "points                     205\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "student_data1 = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'], \n",
    "        'points': [200, 210, 190, 222, 199]})\n",
    "\n",
    "s6 = pd.Series(['S6', 'Scarlette Fisher', 205], index=['student_id', 'name', 'points'])\n",
    "s6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03084d46-4324-417a-bdd4-30c529250b89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Original DataFrames:\")\n",
    "print(student_data1)\n",
    "print(\"\\nNew Row(s)\")\n",
    "print(s6)\n",
    "\n",
    "combined_data = pd.concat([student_data1, s6.to_frame().T], ignore_index=True)\n",
    "# The s6.to_frame().T converts the Series s6 into a DataFrame (transposing it to match the DataFrame's structure).\n",
    "print(\"\\nCombined Data:\")\n",
    "print(combined_data)\n",
    "\n",
    "\n",
    "# pd.concat() combines two dataframes, student_data1 and s6.to_frame().T, and specifying ignore_index=True to reset the index.\n",
    "# s6.to_frame().T: s6 is a Series, and you are converting it to a DataFrame using .to_frame(), followed by .T to transpose it, turning the Series into a single-row DataFrame.\n",
    "# ignore_index=True: ensures that the resulting DataFrame has a continuous index, ignoring the original indices from both student_data1 and s6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c632b2-122f-4904-badd-6f308eef0e00",
   "metadata": {},
   "source": [
    "#### QUESTION 15\n",
    "\n",
    "#### Write a Pandas program to join the two dataframes with matching records from both sides where available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79f72c60-3946-4d67-a852-e07d6dbe51bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "student_data1 = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'], \n",
    "        'marks': [200, 210, 190, 222, 199]})\n",
    "\n",
    "student_data2 = pd.DataFrame({\n",
    "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
    "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'], \n",
    "        'marks': [201, 200, 198, 219, 201]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5739e30-65d9-427c-a495-586a03eebce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      " Dataset 1   student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      " Dataset 2   student_id              name  marks\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n",
      "Merged data (outer join):\n",
      "  student_id            name_x  marks_x            name_y  marks_y\n",
      "0         S1  Danniella Fenton    200.0               NaN      NaN\n",
      "1         S2      Ryder Storey    210.0               NaN      NaN\n",
      "2         S3      Bryce Jensen    190.0               NaN      NaN\n",
      "3         S4         Ed Bernal    222.0  Scarlette Fisher    201.0\n",
      "4         S5       Kwame Morin    199.0  Carla Williamson    200.0\n",
      "5         S6               NaN      NaN       Dante Morse    198.0\n",
      "6         S7               NaN      NaN    Kaiser William    219.0\n",
      "7         S8               NaN      NaN   Madeeha Preston    201.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Original DataFrames:\")\n",
    "print(\" Dataset 1\", student_data1)\n",
    "print( \" Dataset 2\",student_data2)\n",
    "\n",
    "# # Merging using an outer join on 'student_id'\n",
    "merged_data = pd.merge(student_data1, student_data2, on='student_id', how='outer')\n",
    "print(\"Merged data (outer join):\")\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65551bc3-7577-4cd4-af35-ad33cfb05ecf",
   "metadata": {},
   "source": [
    "#### QUESTION 16\n",
    "\n",
    "#### Write a  Pandas program to merge two given datasets using multiple join keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0660ad7d-33b8-45e5-846a-d6fbd625d3f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                     'P': ['P0', 'P1', 'P2', 'P3'],\n",
    "                     'Q': ['Q0', 'Q1', 'Q2', 'Q3']}) \n",
    "\n",
    "\n",
    "data2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                      'R': ['R0', 'R1', 'R2', 'R3'],\n",
    "                      'S': ['S0', 'S1', 'S2', 'S3']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cb94e8d-38b2-49c0-96b7-5e2aaafd998b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key1 key2   P   Q   R   S\n",
      "0   K0   K0  P0  Q0  R0  S0\n",
      "1   K1   K0  P2  Q2  R1  S1\n",
      "2   K1   K0  P2  Q2  R2  S2\n"
     ]
    }
   ],
   "source": [
    "#merges data1 and data2 based on the matching values in both key1 and key2 columns. Only the rows where both key1 and key2 match in both DataFrames will appear in the result.\n",
    "\n",
    "merged_data = pd.merge(data1, data2, on=['key1', 'key2'])\n",
    "print(merged_data)\n",
    "\n",
    "\n",
    "# to include unmatched rows (e.g., rows that appear in one DataFrame but not the other), use how='outer' for an outer join, or how='left' or how='right' for left or right joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f62c59-45b6-4106-af0a-c4a0a6a21087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
